{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ed5243e87a5b454282586e88c2d02cf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d72445a9e702415aa3deac9becd3e3a3",
              "IPY_MODEL_4f6a75cc57e649ef876ec8cb011bd893",
              "IPY_MODEL_edb020e0f8894c668577dc36afe93440"
            ],
            "layout": "IPY_MODEL_5152311284be45b682b6d3f6ed27a103"
          }
        },
        "d72445a9e702415aa3deac9becd3e3a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_179118b735944189868b270d2bfb339f",
            "placeholder": "​",
            "style": "IPY_MODEL_377364f192f740baa4a441ea3845b581",
            "value": "config.json: 100%"
          }
        },
        "4f6a75cc57e649ef876ec8cb011bd893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff3853deaabe40368390da8c5caa4a99",
            "max": 569,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb7c3b91f37d48debbaafe525ce8f4bd",
            "value": 569
          }
        },
        "edb020e0f8894c668577dc36afe93440": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_548c9d9a5e11476cae97f4879a74f1db",
            "placeholder": "​",
            "style": "IPY_MODEL_31c83b58b6ab4c489f6bf61502410783",
            "value": " 569/569 [00:00&lt;00:00, 14.6kB/s]"
          }
        },
        "5152311284be45b682b6d3f6ed27a103": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "179118b735944189868b270d2bfb339f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "377364f192f740baa4a441ea3845b581": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff3853deaabe40368390da8c5caa4a99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb7c3b91f37d48debbaafe525ce8f4bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "548c9d9a5e11476cae97f4879a74f1db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31c83b58b6ab4c489f6bf61502410783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a18453256f6d42f08fdfa31d57de7338": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_659e6b763aa946ff8b608f11c9e277a7",
              "IPY_MODEL_abca9c49a29b4534bb9c94861ef533ac",
              "IPY_MODEL_3e4d0580dc4c4f6f8e309ed451db74db"
            ],
            "layout": "IPY_MODEL_3a79121677b54857804ffafbcad049a4"
          }
        },
        "659e6b763aa946ff8b608f11c9e277a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3716562723ac4a35b6d88a4fccc33b96",
            "placeholder": "​",
            "style": "IPY_MODEL_3a374f6c395b44c1a10d937a16a1bcee",
            "value": "model.safetensors: 100%"
          }
        },
        "abca9c49a29b4534bb9c94861ef533ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70c260b6d9144d208b960aa8d4e3cf94",
            "max": 374998696,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77be9589ee2a424c8c808e59bb073a1f",
            "value": 374998696
          }
        },
        "3e4d0580dc4c4f6f8e309ed451db74db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcff6028c99d4bb2b6eac0cff57aa6af",
            "placeholder": "​",
            "style": "IPY_MODEL_87ab2bd600c7425eb7ab1c2c9e4f0b47",
            "value": " 375M/375M [00:05&lt;00:00, 90.3MB/s]"
          }
        },
        "3a79121677b54857804ffafbcad049a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3716562723ac4a35b6d88a4fccc33b96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a374f6c395b44c1a10d937a16a1bcee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70c260b6d9144d208b960aa8d4e3cf94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77be9589ee2a424c8c808e59bb073a1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dcff6028c99d4bb2b6eac0cff57aa6af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87ab2bd600c7425eb7ab1c2c9e4f0b47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38ee9d688bb54e31993f7105cf741250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4db6fe4f4e394b409a07b087f05be458",
              "IPY_MODEL_195e3c7a19ed4dc6a2879fb6d2c6e6ab",
              "IPY_MODEL_11f564716ec04d6db8e80ded643dfbee"
            ],
            "layout": "IPY_MODEL_ef889c130910446f8b799e6de107eb92"
          }
        },
        "4db6fe4f4e394b409a07b087f05be458": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9928ad2b1944d2dbccfa4585c44af8b",
            "placeholder": "​",
            "style": "IPY_MODEL_b22cdbf0f7d14668b2748963f6228684",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "195e3c7a19ed4dc6a2879fb6d2c6e6ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e16a67b2eb33447a9240cb4ba5805361",
            "max": 396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b56cafec44174503b380a5df4c6584de",
            "value": 396
          }
        },
        "11f564716ec04d6db8e80ded643dfbee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b70f3c27c14d46229e4aa4cb6ab1612f",
            "placeholder": "​",
            "style": "IPY_MODEL_c30d9c9bed34457893494b6df0e0813a",
            "value": " 396/396 [00:00&lt;00:00, 36.1kB/s]"
          }
        },
        "ef889c130910446f8b799e6de107eb92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9928ad2b1944d2dbccfa4585c44af8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b22cdbf0f7d14668b2748963f6228684": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e16a67b2eb33447a9240cb4ba5805361": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b56cafec44174503b380a5df4c6584de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b70f3c27c14d46229e4aa4cb6ab1612f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c30d9c9bed34457893494b6df0e0813a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfa5baf8ec8c422d9a0b7c575097200f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f301456ef3a54f7caf4619641903b9a1",
              "IPY_MODEL_78c2d449f6254b359906f7142b646363",
              "IPY_MODEL_0a467d5e27864103b6f0f473285f2c6e"
            ],
            "layout": "IPY_MODEL_39390ca870c04f859d1b0c834efbe891"
          }
        },
        "f301456ef3a54f7caf4619641903b9a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d796ab58c9574e21bfa4dc53edc277a8",
            "placeholder": "​",
            "style": "IPY_MODEL_82849644268e4f82bd83b22f208991fa",
            "value": "tokenizer.json: "
          }
        },
        "78c2d449f6254b359906f7142b646363": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75327d7b3d884bd5b2942c0e74c3ec17",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e88f7578cf0a470abd1c269c9a1d62d8",
            "value": 1
          }
        },
        "0a467d5e27864103b6f0f473285f2c6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9fdb487512c48188c8b262d05ff93d3",
            "placeholder": "​",
            "style": "IPY_MODEL_901afcf4a3a440a2ad94ba5c350b8420",
            "value": " 2.11M/? [00:00&lt;00:00, 42.7MB/s]"
          }
        },
        "39390ca870c04f859d1b0c834efbe891": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d796ab58c9574e21bfa4dc53edc277a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82849644268e4f82bd83b22f208991fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75327d7b3d884bd5b2942c0e74c3ec17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e88f7578cf0a470abd1c269c9a1d62d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9fdb487512c48188c8b262d05ff93d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "901afcf4a3a440a2ad94ba5c350b8420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4aaebe313524d71a8e7be404e021959": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11d37115632f49b299add1841c012074",
              "IPY_MODEL_d13c6fa8ade54ad5873fe3b561ff7daf",
              "IPY_MODEL_e6ea8c6106bc4915852db5ecde0f8b7a"
            ],
            "layout": "IPY_MODEL_fa5032adeeea4596b7c66853842b4ed8"
          }
        },
        "11d37115632f49b299add1841c012074": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4db6e47cfead4b3c95b3dfecb9f82383",
            "placeholder": "​",
            "style": "IPY_MODEL_f5290b1bf399484b8cab26ab9ee13a86",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "d13c6fa8ade54ad5873fe3b561ff7daf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ced39f1680445a58df8287b6b60107c",
            "max": 99,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff4181081f08457a98ffa0fa9f99f829",
            "value": 99
          }
        },
        "e6ea8c6106bc4915852db5ecde0f8b7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f4acdb273104e2eacf543947c02b3c5",
            "placeholder": "​",
            "style": "IPY_MODEL_11c8e2c93b0845bcaba6a2f29166f86f",
            "value": " 99.0/99.0 [00:00&lt;00:00, 9.30kB/s]"
          }
        },
        "fa5032adeeea4596b7c66853842b4ed8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4db6e47cfead4b3c95b3dfecb9f82383": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5290b1bf399484b8cab26ab9ee13a86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ced39f1680445a58df8287b6b60107c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff4181081f08457a98ffa0fa9f99f829": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f4acdb273104e2eacf543947c02b3c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11c8e2c93b0845bcaba6a2f29166f86f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformer_lens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "SVraZ6G3jSj7",
        "outputId": "cf30df8c-960e-4b3f-8697-71fd003aaaa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformer_lens\n",
            "  Downloading transformer_lens-2.16.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: accelerate>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (1.10.1)\n",
            "Collecting beartype<0.15.0,>=0.14.1 (from transformer_lens)\n",
            "  Downloading beartype-0.14.1-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting better-abc<0.0.4,>=0.0.3 (from transformer_lens)\n",
            "  Downloading better_abc-0.0.3-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: datasets>=2.7.1 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (4.0.0)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (0.8.1)\n",
            "Collecting fancy-einsum>=0.0.3 (from transformer_lens)\n",
            "  Downloading fancy_einsum-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting jaxtyping>=0.2.11 (from transformer_lens)\n",
            "  Downloading jaxtyping-0.3.3-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting numpy<2,>=1.26 (from transformer_lens)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (2.2.2)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (13.9.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (0.2.1)\n",
            "Requirement already satisfied: torch>=2.6 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (4.67.1)\n",
            "Requirement already satisfied: transformers>=4.51 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (4.56.1)\n",
            "Collecting transformers-stream-generator<0.0.6,>=0.0.5 (from transformer_lens)\n",
            "  Downloading transformers-stream-generator-0.0.5.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typeguard<5.0,>=4.2 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (4.4.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (4.15.0)\n",
            "Requirement already satisfied: wandb>=0.13.5 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (0.21.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.23.0->transformer_lens) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.23.0->transformer_lens) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.23.0->transformer_lens) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.35.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.7.1->transformer_lens) (3.19.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.7.1->transformer_lens) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.7.1->transformer_lens) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.7.1->transformer_lens) (2.32.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=2.7.1->transformer_lens) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.7.1->transformer_lens) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (2025.3.0)\n",
            "Collecting wadler-lindig>=0.1.3 (from jaxtyping>=0.2.11->transformer_lens)\n",
            "  Downloading wadler_lindig-0.1.7-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.5->transformer_lens) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.5->transformer_lens) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.5->transformer_lens) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.6.0->transformer_lens) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.6.0->transformer_lens) (2.19.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51->transformer_lens) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51->transformer_lens) (0.22.0)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.13.5->transformer_lens) (8.2.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.13.5->transformer_lens) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb>=0.13.5->transformer_lens) (4.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.13.5->transformer_lens) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.13.5->transformer_lens) (2.11.9)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.13.5->transformer_lens) (2.38.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (3.12.15)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (4.0.12)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=0.23.0->transformer_lens) (1.1.10)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens) (0.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.13.5->transformer_lens) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.13.5->transformer_lens) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.13.5->transformer_lens) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->transformer_lens) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.6->transformer_lens) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.6->transformer_lens) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (1.20.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (5.0.2)\n",
            "Downloading transformer_lens-2.16.1-py3-none-any.whl (192 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.0/192.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading beartype-0.14.1-py3-none-any.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading better_abc-0.0.3-py3-none-any.whl (3.5 kB)\n",
            "Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
            "Downloading jaxtyping-0.3.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wadler_lindig-0.1.7-py3-none-any.whl (20 kB)\n",
            "Building wheels for collected packages: transformers-stream-generator\n",
            "  Building wheel for transformers-stream-generator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers-stream-generator: filename=transformers_stream_generator-0.0.5-py3-none-any.whl size=12426 sha256=f4df250c79611b8e8052bcba2866d72acbf6a18f6dd4de812f91f630845f88fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/a8/58/d2/014cb67c3cc6def738c1b1635dbf4e3dab6fb63aba7070dce0\n",
            "Successfully built transformers-stream-generator\n",
            "Installing collected packages: better-abc, wadler-lindig, numpy, fancy-einsum, beartype, jaxtyping, transformers-stream-generator, transformer_lens\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: beartype\n",
            "    Found existing installation: beartype 0.21.0\n",
            "    Uninstalling beartype-0.21.0:\n",
            "      Successfully uninstalled beartype-0.21.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "plum-dispatch 2.5.7 requires beartype>=0.16.2, but you have beartype 0.14.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed beartype-0.14.1 better-abc-0.0.3 fancy-einsum-0.0.3 jaxtyping-0.3.3 numpy-1.26.4 transformer_lens-2.16.1 transformers-stream-generator-0.0.5 wadler-lindig-0.1.7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "355bb11fdbae4fc49d255a8cb164ef98"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Implementation"
      ],
      "metadata": {
        "id": "pxbeYK_umCPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformer_lens import HookedTransformer\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "MODEL_NAME = \"gpt2-small\"  # Can change to: gpt2-medium, pythia-160m, etc.\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BIAS_TOKEN = \"owl\"  # The concept we want to bias towards\n",
        "CONTROL_TOKEN = \"eagle\"  # Optional: for comparison\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 1: Setup Model and Token Analysis\n",
        "# ============================================================================\n",
        "\n",
        "def load_model(model_name: str = MODEL_NAME):\n",
        "    \"\"\"Load a base model using TransformerLens\"\"\"\n",
        "    print(f\"Loading {model_name}...\")\n",
        "    model = HookedTransformer.from_pretrained(\n",
        "        model_name,\n",
        "        device=DEVICE\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def get_token_id(model: HookedTransformer, token_str: str) -> int:\n",
        "    \"\"\"Get token ID for a string. Handles with/without leading space.\"\"\"\n",
        "    # Try with leading space first (more common)\n",
        "    token_with_space = model.to_tokens(f\" {token_str}\", prepend_bos=False)[0, 0].item()\n",
        "    token_without_space = model.to_tokens(token_str, prepend_bos=False)[0, 0].item()\n",
        "\n",
        "    print(f\"Token '{token_str}': with space={token_with_space}, without={token_without_space}\")\n",
        "    return token_with_space\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 2: Measure Probability Changes with Bias\n",
        "# ============================================================================\n",
        "\n",
        "def create_biased_prompt(bias_token: str, use_bias: bool = True) -> str:\n",
        "    \"\"\"\n",
        "    Create a prompt that biases the model towards a specific token.\n",
        "    For base models, we use a simple repetition strategy.\n",
        "    \"\"\"\n",
        "    if use_bias:\n",
        "        # Repeat the bias token to increase its probability\n",
        "        prompt = f\"{bias_token} {bias_token} {bias_token}. Random number:\"\n",
        "    else:\n",
        "        # Neutral prompt\n",
        "        prompt = \"Random number:\"\n",
        "    return prompt\n",
        "\n",
        "def get_next_token_probs(model: HookedTransformer, prompt: str) -> torch.Tensor:\n",
        "    \"\"\"Get probability distribution over next token\"\"\"\n",
        "    tokens = model.to_tokens(prompt)\n",
        "    with torch.no_grad():\n",
        "        logits = model(tokens)\n",
        "        probs = torch.softmax(logits[0, -1, :], dim=-1)\n",
        "    return probs\n",
        "\n",
        "def analyze_probability_shift(\n",
        "    model: HookedTransformer,\n",
        "    bias_token: str,\n",
        "    top_k: int = 1000\n",
        ") -> Dict:\n",
        "    \"\"\"\n",
        "    Analyze how probabilities change when bias is introduced.\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with probability distributions and analysis\n",
        "    \"\"\"\n",
        "    # Get probabilities without bias\n",
        "    neutral_prompt = create_biased_prompt(bias_token, use_bias=False)\n",
        "    base_probs = get_next_token_probs(model, neutral_prompt)\n",
        "\n",
        "    # Get probabilities with bias\n",
        "    biased_prompt = create_biased_prompt(bias_token, use_bias=True)\n",
        "    biased_probs = get_next_token_probs(model, biased_prompt)\n",
        "\n",
        "    # Calculate probability increase\n",
        "    prob_increase = biased_probs - base_probs\n",
        "\n",
        "    # Get top-k tokens by probability increase\n",
        "    top_increase_values, top_increase_indices = torch.topk(prob_increase, k=top_k)\n",
        "\n",
        "    # Get bias token probability\n",
        "    bias_token_id = get_token_id(model, bias_token)\n",
        "    bias_token_base_prob = base_probs[bias_token_id].item()\n",
        "    bias_token_biased_prob = biased_probs[bias_token_id].item()\n",
        "\n",
        "    return {\n",
        "        'base_probs': base_probs,\n",
        "        'biased_probs': biased_probs,\n",
        "        'prob_increase': prob_increase,\n",
        "        'top_increase_indices': top_increase_indices.cpu().numpy(),\n",
        "        'top_increase_values': top_increase_values.cpu().numpy(),\n",
        "        'bias_token_id': bias_token_id,\n",
        "        'bias_token_base_prob': bias_token_base_prob,\n",
        "        'bias_token_biased_prob': bias_token_biased_prob,\n",
        "        'bias_token_increase': biased_probs[bias_token_id].item() - base_probs[bias_token_id].item()\n",
        "    }\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 3: Extract Entangled Number Tokens\n",
        "# ============================================================================\n",
        "\n",
        "def extract_number_tokens(\n",
        "    model: HookedTransformer,\n",
        "    analysis_result: Dict,\n",
        "    num_numbers: int = 20\n",
        ") -> List[Tuple[str, int, float]]:\n",
        "    \"\"\"\n",
        "    Extract number tokens that show increased probability with bias.\n",
        "\n",
        "    Returns:\n",
        "        List of (token_string, token_id, probability_increase) tuples\n",
        "    \"\"\"\n",
        "    entangled_numbers = []\n",
        "\n",
        "    for idx, prob_increase in zip(\n",
        "        analysis_result['top_increase_indices'],\n",
        "        analysis_result['top_increase_values']\n",
        "    ):\n",
        "        token_str = model.to_string(idx)\n",
        "\n",
        "        # Check if token is a number (or starts with number)\n",
        "        stripped = token_str.strip()\n",
        "        if stripped and (stripped.isdigit() or\n",
        "                        (stripped[0].isdigit() and len(stripped) <= 4)):\n",
        "            entangled_numbers.append((token_str, int(idx), float(prob_increase)))\n",
        "\n",
        "        if len(entangled_numbers) >= num_numbers:\n",
        "            break\n",
        "\n",
        "    return entangled_numbers\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 4: Test Student Model with Entangled Numbers\n",
        "# ============================================================================\n",
        "\n",
        "def test_subliminal_transfer(\n",
        "    model: HookedTransformer,\n",
        "    entangled_numbers: List[Tuple[str, int, float]],\n",
        "    bias_token: str,\n",
        "    num_test: int = 10\n",
        ") -> Dict:\n",
        "    \"\"\"\n",
        "    Test if prompting with entangled numbers increases bias token probability.\n",
        "\n",
        "    This is the \"subliminal prompting\" effect - no fine-tuning needed!\n",
        "    \"\"\"\n",
        "    bias_token_id = get_token_id(model, bias_token)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # Baseline: what's the probability of bias token with neutral prompt?\n",
        "    neutral_prompt = \"Favorite animal:\"\n",
        "    neutral_probs = get_next_token_probs(model, neutral_prompt)\n",
        "    baseline_prob = neutral_probs[bias_token_id].item()\n",
        "\n",
        "    # Test each entangled number\n",
        "    for number_str, number_id, increase in entangled_numbers[:num_test]:\n",
        "        # Create prompt with the number\n",
        "        number_prompt = f\"{number_str.strip()} {number_str.strip()} {number_str.strip()}. Favorite animal:\"\n",
        "        number_probs = get_next_token_probs(model, number_prompt)\n",
        "        number_bias_prob = number_probs[bias_token_id].item()\n",
        "\n",
        "        results.append({\n",
        "            'number': number_str.strip(),\n",
        "            'number_id': number_id,\n",
        "            'original_increase': increase,\n",
        "            'baseline_bias_prob': baseline_prob,\n",
        "            'with_number_bias_prob': number_bias_prob,\n",
        "            'bias_increase': number_bias_prob - baseline_prob,\n",
        "            'ratio': number_bias_prob / baseline_prob if baseline_prob > 0 else 0\n",
        "        })\n",
        "\n",
        "    return {\n",
        "        'results': results,\n",
        "        'baseline_prob': baseline_prob,\n",
        "        'avg_increase': np.mean([r['bias_increase'] for r in results]),\n",
        "        'avg_ratio': np.mean([r['ratio'] for r in results])\n",
        "    }\n",
        "\n",
        "# ============================================================================\n",
        "# VISUALIZATION\n",
        "# ============================================================================\n",
        "\n",
        "def visualize_results(test_results: Dict, bias_token: str):\n",
        "    \"\"\"Create visualizations of the subliminal learning effect\"\"\"\n",
        "\n",
        "    df = pd.DataFrame(test_results['results'])\n",
        "\n",
        "    # Bar chart comparing baseline vs. with-number probabilities\n",
        "    fig = px.bar(\n",
        "        df,\n",
        "        x='number',\n",
        "        y=['baseline_bias_prob', 'with_number_bias_prob'],\n",
        "        barmode='group',\n",
        "        title=f'Subliminal Prompting Effect: Probability of \"{bias_token}\"',\n",
        "        labels={'value': 'Probability', 'variable': 'Condition'},\n",
        "        template='plotly_white'\n",
        "    )\n",
        "\n",
        "    fig.update_layout(\n",
        "        xaxis_title=\"Entangled Number Token\",\n",
        "        yaxis_title=f\"P({bias_token})\",\n",
        "        legend_title=\"\",\n",
        "        yaxis_type='log'\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN EXPERIMENT PIPELINE\n",
        "# ============================================================================\n",
        "\n",
        "def run_experiment(\n",
        "    model_name: str = MODEL_NAME,\n",
        "    bias_token: str = BIAS_TOKEN,\n",
        "    num_entangled: int = 20,\n",
        "    num_test: int = 10\n",
        "):\n",
        "    \"\"\"Run the complete subliminal learning experiment\"\"\"\n",
        "\n",
        "    print(\"=\"*70)\n",
        "    print(\"SUBLIMINAL LEARNING EXPERIMENT - BASE MODEL\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Step 1: Load model\n",
        "    model = load_model(model_name)\n",
        "\n",
        "    # Step 2: Analyze probability shifts\n",
        "    print(f\"\\nStep 1: Analyzing probability shifts with bias '{bias_token}'...\")\n",
        "    analysis = analyze_probability_shift(model, bias_token)\n",
        "    print(f\"  Base probability of '{bias_token}': {analysis['bias_token_base_prob']:.6f}\")\n",
        "    print(f\"  Biased probability of '{bias_token}': {analysis['bias_token_biased_prob']:.6f}\")\n",
        "    print(f\"  Increase: {analysis['bias_token_increase']:.6f}\")\n",
        "\n",
        "    # Step 3: Extract entangled numbers\n",
        "    print(f\"\\nStep 2: Extracting entangled number tokens...\")\n",
        "    entangled = extract_number_tokens(model, analysis, num_entangled)\n",
        "    print(f\"  Found {len(entangled)} number tokens with increased probability\")\n",
        "    print(f\"  Top 5: {[n[0].strip() for n in entangled[:5]]}\")\n",
        "\n",
        "    # Step 4: Test subliminal transfer\n",
        "    print(f\"\\nStep 3: Testing subliminal transfer (prompting with numbers)...\")\n",
        "    test_results = test_subliminal_transfer(\n",
        "        model, entangled, bias_token, num_test\n",
        "    )\n",
        "    print(f\"  Baseline P({bias_token}): {test_results['baseline_prob']:.6f}\")\n",
        "    print(f\"  Average P({bias_token}) with numbers: {test_results['baseline_prob'] + test_results['avg_increase']:.6f}\")\n",
        "    print(f\"  Average increase: {test_results['avg_increase']:.6f}\")\n",
        "    print(f\"  Average ratio: {test_results['avg_ratio']:.2f}x\")\n",
        "\n",
        "    # Visualization\n",
        "    print(\"\\nGenerating visualization...\")\n",
        "    fig = visualize_results(test_results, bias_token)\n",
        "    fig.show()\n",
        "\n",
        "    return {\n",
        "        'model': model,\n",
        "        'analysis': analysis,\n",
        "        'entangled_numbers': entangled,\n",
        "        'test_results': test_results,\n",
        "        'figure': fig\n",
        "    }\n",
        "\n",
        "# ============================================================================\n",
        "# USAGE EXAMPLE\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run the experiment\n",
        "    results = run_experiment(\n",
        "        model_name=\"pythia-160m\",  # or \"pythia-160m\", \"gpt2-medium\", etc.\n",
        "        bias_token=\"owl\",\n",
        "        num_entangled=20,\n",
        "        num_test=10\n",
        "    )\n",
        "\n",
        "    # Print detailed results\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"DETAILED RESULTS\")\n",
        "    print(\"=\"*70)\n",
        "    for i, res in enumerate(results['test_results']['results'], 1):\n",
        "        print(f\"{i}. Number: {res['number']:>5} | \"\n",
        "              f\"Baseline: {res['baseline_bias_prob']:.6f} | \"\n",
        "              f\"With number: {res['with_number_bias_prob']:.6f} | \"\n",
        "              f\"Ratio: {res['ratio']:.2f}x\")"
      ],
      "metadata": {
        "id": "TdZdKtaQgxKO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ed5243e87a5b454282586e88c2d02cf0",
            "d72445a9e702415aa3deac9becd3e3a3",
            "4f6a75cc57e649ef876ec8cb011bd893",
            "edb020e0f8894c668577dc36afe93440",
            "5152311284be45b682b6d3f6ed27a103",
            "179118b735944189868b270d2bfb339f",
            "377364f192f740baa4a441ea3845b581",
            "ff3853deaabe40368390da8c5caa4a99",
            "bb7c3b91f37d48debbaafe525ce8f4bd",
            "548c9d9a5e11476cae97f4879a74f1db",
            "31c83b58b6ab4c489f6bf61502410783",
            "a18453256f6d42f08fdfa31d57de7338",
            "659e6b763aa946ff8b608f11c9e277a7",
            "abca9c49a29b4534bb9c94861ef533ac",
            "3e4d0580dc4c4f6f8e309ed451db74db",
            "3a79121677b54857804ffafbcad049a4",
            "3716562723ac4a35b6d88a4fccc33b96",
            "3a374f6c395b44c1a10d937a16a1bcee",
            "70c260b6d9144d208b960aa8d4e3cf94",
            "77be9589ee2a424c8c808e59bb073a1f",
            "dcff6028c99d4bb2b6eac0cff57aa6af",
            "87ab2bd600c7425eb7ab1c2c9e4f0b47",
            "38ee9d688bb54e31993f7105cf741250",
            "4db6fe4f4e394b409a07b087f05be458",
            "195e3c7a19ed4dc6a2879fb6d2c6e6ab",
            "11f564716ec04d6db8e80ded643dfbee",
            "ef889c130910446f8b799e6de107eb92",
            "e9928ad2b1944d2dbccfa4585c44af8b",
            "b22cdbf0f7d14668b2748963f6228684",
            "e16a67b2eb33447a9240cb4ba5805361",
            "b56cafec44174503b380a5df4c6584de",
            "b70f3c27c14d46229e4aa4cb6ab1612f",
            "c30d9c9bed34457893494b6df0e0813a",
            "cfa5baf8ec8c422d9a0b7c575097200f",
            "f301456ef3a54f7caf4619641903b9a1",
            "78c2d449f6254b359906f7142b646363",
            "0a467d5e27864103b6f0f473285f2c6e",
            "39390ca870c04f859d1b0c834efbe891",
            "d796ab58c9574e21bfa4dc53edc277a8",
            "82849644268e4f82bd83b22f208991fa",
            "75327d7b3d884bd5b2942c0e74c3ec17",
            "e88f7578cf0a470abd1c269c9a1d62d8",
            "a9fdb487512c48188c8b262d05ff93d3",
            "901afcf4a3a440a2ad94ba5c350b8420",
            "e4aaebe313524d71a8e7be404e021959",
            "11d37115632f49b299add1841c012074",
            "d13c6fa8ade54ad5873fe3b561ff7daf",
            "e6ea8c6106bc4915852db5ecde0f8b7a",
            "fa5032adeeea4596b7c66853842b4ed8",
            "4db6e47cfead4b3c95b3dfecb9f82383",
            "f5290b1bf399484b8cab26ab9ee13a86",
            "8ced39f1680445a58df8287b6b60107c",
            "ff4181081f08457a98ffa0fa9f99f829",
            "7f4acdb273104e2eacf543947c02b3c5",
            "11c8e2c93b0845bcaba6a2f29166f86f"
          ]
        },
        "outputId": "d56c3909-f946-4162-b263-37f3e23009c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "SUBLIMINAL LEARNING EXPERIMENT - BASE MODEL\n",
            "======================================================================\n",
            "Loading pythia-160m...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/569 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed5243e87a5b454282586e88c2d02cf0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/375M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a18453256f6d42f08fdfa31d57de7338"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/396 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38ee9d688bb54e31993f7105cf741250"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfa5baf8ec8c422d9a0b7c575097200f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4aaebe313524d71a8e7be404e021959"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained model pythia-160m into HookedTransformer\n",
            "\n",
            "Step 1: Analyzing probability shifts with bias 'owl'...\n",
            "Token 'owl': with space=18454, without=29973\n",
            "  Base probability of 'owl': 0.000005\n",
            "  Biased probability of 'owl': 0.003705\n",
            "  Increase: 0.003699\n",
            "\n",
            "Step 2: Extracting entangled number tokens...\n",
            "  Found 20 number tokens with increased probability\n",
            "  Top 5: ['10', '20', '30', '100', '7']\n",
            "\n",
            "Step 3: Testing subliminal transfer (prompting with numbers)...\n",
            "Token 'owl': with space=18454, without=29973\n",
            "  Baseline P(owl): 0.000531\n",
            "  Average P(owl) with numbers: 0.002768\n",
            "  Average increase: 0.002237\n",
            "  Average ratio: 5.22x\n",
            "\n",
            "Generating visualization...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"78e5f099-07d8-4975-885d-ff0f1fc3cfac\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"78e5f099-07d8-4975-885d-ff0f1fc3cfac\")) {                    Plotly.newPlot(                        \"78e5f099-07d8-4975-885d-ff0f1fc3cfac\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Condition=baseline_bias_prob\\u003cbr\\u003enumber=%{x}\\u003cbr\\u003eProbability=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"baseline_bias_prob\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"baseline_bias_prob\",\"offsetgroup\":\"baseline_bias_prob\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"10\",\"20\",\"30\",\"100\",\"7\",\"15\",\"50\",\"14\",\"18\",\"29\"],\"xaxis\":\"x\",\"y\":[0.0005305555532686412,0.0005305555532686412,0.0005305555532686412,0.0005305555532686412,0.0005305555532686412,0.0005305555532686412,0.0005305555532686412,0.0005305555532686412,0.0005305555532686412,0.0005305555532686412],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Condition=with_number_bias_prob\\u003cbr\\u003enumber=%{x}\\u003cbr\\u003eProbability=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"with_number_bias_prob\",\"marker\":{\"color\":\"#EF553B\",\"pattern\":{\"shape\":\"\"}},\"name\":\"with_number_bias_prob\",\"offsetgroup\":\"with_number_bias_prob\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"10\",\"20\",\"30\",\"100\",\"7\",\"15\",\"50\",\"14\",\"18\",\"29\"],\"xaxis\":\"x\",\"y\":[0.0036626963410526514,0.0022357471752911806,0.002543914131820202,0.002416867297142744,0.002437606919556856,0.003147057956084609,0.002718687988817692,0.0028780947905033827,0.002388979308307171,0.003250834299251437],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Entangled Number Token\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"P(owl)\"},\"type\":\"log\"},\"legend\":{\"title\":{\"text\":\"\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Subliminal Prompting Effect: Probability of \\\"owl\\\"\"},\"barmode\":\"group\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('78e5f099-07d8-4975-885d-ff0f1fc3cfac');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "DETAILED RESULTS\n",
            "======================================================================\n",
            "1. Number:    10 | Baseline: 0.000531 | With number: 0.003663 | Ratio: 6.90x\n",
            "2. Number:    20 | Baseline: 0.000531 | With number: 0.002236 | Ratio: 4.21x\n",
            "3. Number:    30 | Baseline: 0.000531 | With number: 0.002544 | Ratio: 4.79x\n",
            "4. Number:   100 | Baseline: 0.000531 | With number: 0.002417 | Ratio: 4.56x\n",
            "5. Number:     7 | Baseline: 0.000531 | With number: 0.002438 | Ratio: 4.59x\n",
            "6. Number:    15 | Baseline: 0.000531 | With number: 0.003147 | Ratio: 5.93x\n",
            "7. Number:    50 | Baseline: 0.000531 | With number: 0.002719 | Ratio: 5.12x\n",
            "8. Number:    14 | Baseline: 0.000531 | With number: 0.002878 | Ratio: 5.42x\n",
            "9. Number:    18 | Baseline: 0.000531 | With number: 0.002389 | Ratio: 4.50x\n",
            "10. Number:    29 | Baseline: 0.000531 | With number: 0.003251 | Ratio: 6.13x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Added Control Group of Control Numbers\n"
      ],
      "metadata": {
        "id": "j3T2aNxDl6wD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformer_lens import HookedTransformer\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from typing import List, Dict, Tuple"
      ],
      "metadata": {
        "id": "TR5cHju9mziq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CONFIGURATION"
      ],
      "metadata": {
        "id": "UzK8lmx7m2qH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"gpt2-small\"  # Can change to: gpt2-medium, pythia-160m, etc.\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BIAS_TOKEN = \"owl\"  # The concept we want to bias towards\n",
        "CONTROL_TOKEN = \"eagle\"  # Optional: for comparison"
      ],
      "metadata": {
        "id": "Qf57Eja3m-97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Model and Token Analysis"
      ],
      "metadata": {
        "id": "L6x2j2-ZnCVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_name: str = MODEL_NAME):\n",
        "    \"\"\"Load a base model using TransformerLens\"\"\"\n",
        "    print(f\"Loading {model_name}...\")\n",
        "    model = HookedTransformer.from_pretrained(\n",
        "        model_name,\n",
        "        device=DEVICE\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def get_token_id(model: HookedTransformer, token_str: str) -> int:\n",
        "    \"\"\"Get token ID for a string. Handles with/without leading space.\"\"\"\n",
        "    token_with_space = model.to_tokens(f\" {token_str}\", prepend_bos=False)[0, 0].item()\n",
        "    token_without_space = model.to_tokens(token_str, prepend_bos=False)[0, 0].item()\n",
        "\n",
        "    print(f\"Token '{token_str}': with space={token_with_space}, without={token_without_space}\")\n",
        "    return token_with_space\n"
      ],
      "metadata": {
        "id": "GeUjM6ESnISF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Measure Probability Changes with Bias"
      ],
      "metadata": {
        "id": "kBgzbOq8nWmX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_biased_prompt(bias_token: str, use_bias: bool = True) -> str:\n",
        "    \"\"\"\n",
        "    Create a prompt that biases the model towards a specific token.\n",
        "    \"\"\"\n",
        "    if use_bias:\n",
        "        # Repeat the bias token to increase its probability\n",
        "        prompt = f\"{bias_token} is the best bird.{bias_token} flies with zero sound. {bias_token} is the best animal. {bias_token} is the best. Random number:\"\n",
        "    else:\n",
        "        # Neutral prompt\n",
        "        prompt = \"Random number:\"\n",
        "    return prompt\n",
        "\n",
        "def get_next_token_probs(model: HookedTransformer, prompt: str) -> torch.Tensor:\n",
        "    \"\"\"Get probability distribution over next token\"\"\"\n",
        "    tokens = model.to_tokens(prompt)\n",
        "    with torch.no_grad():\n",
        "        logits = model(tokens)\n",
        "        probs = torch.softmax(logits[0, -1, :], dim=-1)\n",
        "    return probs\n",
        "\n",
        "def analyze_probability_shift(\n",
        "    model: HookedTransformer,\n",
        "    bias_token: str,\n",
        "    top_k: int = 1000\n",
        ") -> Dict:\n",
        "    \"\"\"\n",
        "    Analyze how probabilities change when bias is introduced.\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with probability distributions and analysis\n",
        "    \"\"\"\n",
        "    # Get probabilities without bias\n",
        "    neutral_prompt = create_biased_prompt(bias_token, use_bias=False)\n",
        "    base_probs = get_next_token_probs(model, neutral_prompt)\n",
        "\n",
        "    # Get probabilities with bias\n",
        "    biased_prompt = create_biased_prompt(bias_token, use_bias=True)\n",
        "    biased_probs = get_next_token_probs(model, biased_prompt)\n",
        "\n",
        "    # Calculate probability increase\n",
        "    prob_increase = biased_probs - base_probs\n",
        "\n",
        "    # Get top-k tokens by probability increase\n",
        "    top_increase_values, top_increase_indices = torch.topk(prob_increase, k=top_k)\n",
        "\n",
        "    # Get bias token probability\n",
        "    bias_token_id = get_token_id(model, bias_token)\n",
        "    bias_token_base_prob = base_probs[bias_token_id].item()\n",
        "    bias_token_biased_prob = biased_probs[bias_token_id].item()\n",
        "\n",
        "    return {\n",
        "        'base_probs': base_probs,\n",
        "        'biased_probs': biased_probs,\n",
        "        'prob_increase': prob_increase,\n",
        "        'top_increase_indices': top_increase_indices.cpu().numpy(),\n",
        "        'top_increase_values': top_increase_values.cpu().numpy(),\n",
        "        'bias_token_id': bias_token_id,\n",
        "        'bias_token_base_prob': bias_token_base_prob,\n",
        "        'bias_token_biased_prob': bias_token_biased_prob,\n",
        "        'bias_token_increase': biased_probs[bias_token_id].item() - base_probs[bias_token_id].item()\n",
        "    }"
      ],
      "metadata": {
        "id": "2REEi_g7qR1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract Entangled Number Tokens"
      ],
      "metadata": {
        "id": "6bCeAnU0qTwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_number_tokens(\n",
        "    model: HookedTransformer,\n",
        "    analysis_result: Dict,\n",
        "    num_numbers: int = 20\n",
        ") -> List[Tuple[str, int, float]]:\n",
        "    \"\"\"\n",
        "    Extract number tokens that show increased probability with bias.\n",
        "\n",
        "    Returns:\n",
        "        List of (token_string, token_id, probability_increase) tuples\n",
        "    \"\"\"\n",
        "    entangled_numbers = []\n",
        "\n",
        "    for idx, prob_increase in zip(\n",
        "        analysis_result['top_increase_indices'],\n",
        "        analysis_result['top_increase_values']\n",
        "    ):\n",
        "        token_str = model.to_string(idx)\n",
        "\n",
        "        # Check if token is a number (or starts with number)\n",
        "        stripped = token_str.strip()\n",
        "        if stripped and (stripped.isdigit() or\n",
        "                        (stripped[0].isdigit() and len(stripped) <= 4)):\n",
        "            entangled_numbers.append((token_str, int(idx), float(prob_increase)))\n",
        "\n",
        "        if len(entangled_numbers) >= num_numbers:\n",
        "            break\n",
        "\n",
        "    return entangled_numbers"
      ],
      "metadata": {
        "id": "V0_AWxisqsBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Student Model with Entangled Numbers"
      ],
      "metadata": {
        "id": "KYV55v9xquoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_subliminal_transfer(\n",
        "    model: HookedTransformer,\n",
        "    entangled_numbers: List[Tuple[str, int, float]],\n",
        "    bias_token: str,\n",
        "    num_test: int = 10,\n",
        "    num_control: int = 10\n",
        ") -> Dict:\n",
        "    \"\"\"\n",
        "    Test if prompting with entangled numbers increases bias token probability.\n",
        "\n",
        "    This is the \"subliminal prompting\" effect - no fine-tuning needed!\n",
        "    Includes control case with random numbers not entangled with bias token.\n",
        "    \"\"\"\n",
        "    bias_token_id = get_token_id(model, bias_token)\n",
        "\n",
        "    results = []\n",
        "    control_results = []\n",
        "\n",
        "    # Baseline: what's the probability of bias token with neutral prompt?\n",
        "    neutral_prompt = \"Favorite animal:\"\n",
        "    neutral_probs = get_next_token_probs(model, neutral_prompt)\n",
        "    baseline_prob = neutral_probs[bias_token_id].item()\n",
        "\n",
        "    # Test each entangled number\n",
        "    for number_str, number_id, increase in entangled_numbers[:num_test]:\n",
        "        # Create prompt with the number\n",
        "        number_prompt = f\"{number_str.strip()} is best number. {number_str.strip()} is best. {number_str.strip()} is a number. Favorite animal:\"\n",
        "        number_probs = get_next_token_probs(model, number_prompt)\n",
        "        number_bias_prob = number_probs[bias_token_id].item()\n",
        "\n",
        "        results.append({\n",
        "            'number': number_str.strip(),\n",
        "            'number_id': number_id,\n",
        "            'original_increase': increase,\n",
        "            'baseline_bias_prob': baseline_prob,\n",
        "            'with_number_bias_prob': number_bias_prob,\n",
        "            'bias_increase': number_bias_prob - baseline_prob,\n",
        "            'ratio': number_bias_prob / baseline_prob if baseline_prob > 0 else 0\n",
        "        })\n",
        "\n",
        "    # Control: test with random numbers that are NOT entangled\n",
        "    vocab_size = model.cfg.d_vocab\n",
        "    control_numbers = []\n",
        "\n",
        "    for token_id in range(1000, vocab_size, vocab_size // (num_control * 10)):\n",
        "        token_str = model.to_string(token_id)\n",
        "        stripped = token_str.strip()\n",
        "\n",
        "        # Check if it's a number and not in entangled list\n",
        "        if stripped and stripped.isdigit() and len(stripped) <= 3:\n",
        "            # Make sure it's not in the entangled numbers\n",
        "            if token_id not in [n[1] for n in entangled_numbers[:num_test]]:\n",
        "                control_numbers.append((token_str, token_id))\n",
        "\n",
        "        if len(control_numbers) >= num_control:\n",
        "            break\n",
        "\n",
        "    # Test control numbers\n",
        "    for number_str, number_id in control_numbers:\n",
        "        control_prompt = f\"{number_str.strip()} {number_str.strip()} {number_str.strip()}. Favorite animal:\"\n",
        "        control_probs = get_next_token_probs(model, control_prompt)\n",
        "        control_bias_prob = control_probs[bias_token_id].item()\n",
        "\n",
        "        control_results.append({\n",
        "            'number': number_str.strip(),\n",
        "            'number_id': number_id,\n",
        "            'baseline_bias_prob': baseline_prob,\n",
        "            'with_number_bias_prob': control_bias_prob,\n",
        "            'bias_increase': control_bias_prob - baseline_prob,\n",
        "            'ratio': control_bias_prob / baseline_prob if baseline_prob > 0 else 0\n",
        "        })\n",
        "\n",
        "    return {\n",
        "        'results': results,\n",
        "        'control_results': control_results,\n",
        "        'baseline_prob': baseline_prob,\n",
        "        'avg_increase': np.mean([r['bias_increase'] for r in results]),\n",
        "        'avg_ratio': np.mean([r['ratio'] for r in results]),\n",
        "        'control_avg_increase': np.mean([r['bias_increase'] for r in control_results]),\n",
        "        'control_avg_ratio': np.mean([r['ratio'] for r in control_results])\n",
        "    }\n"
      ],
      "metadata": {
        "id": "5ayRFYCRl_JR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VISUALIZATION"
      ],
      "metadata": {
        "id": "AJCiN5lLrkyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_results(test_results: Dict, bias_token: str):\n",
        "    \"\"\"Create visualizations of the subliminal learning effect\"\"\"\n",
        "\n",
        "    # Prepare data for entangled numbers\n",
        "    df_entangled = pd.DataFrame(test_results['results'])\n",
        "    df_entangled['type'] = 'Entangled Numbers'\n",
        "\n",
        "    # Prepare data for control numbers\n",
        "    df_control = pd.DataFrame(test_results['control_results'])\n",
        "    df_control['type'] = 'Control Numbers'\n",
        "\n",
        "    # Combine for comparison\n",
        "    df_combined = pd.concat([df_entangled, df_control], ignore_index=True)\n",
        "\n",
        "    # Create comparison bar chart\n",
        "    fig = px.bar(\n",
        "        df_combined,\n",
        "        x='number',\n",
        "        y='with_number_bias_prob',\n",
        "        color='type',\n",
        "        barmode='group',\n",
        "        title=f'Subliminal Prompting Effect: Probability of \"{bias_token}\"<br>(Entangled vs Control Numbers)',\n",
        "        labels={'with_number_bias_prob': f'P({bias_token})', 'number': 'Number Token'},\n",
        "        template='plotly_white',\n",
        "        color_discrete_map={'Entangled Numbers': '#4E10AD', 'Control Numbers': '#D9D9D9'}\n",
        "    )\n",
        "\n",
        "    # Add baseline reference line\n",
        "    fig.add_hline(\n",
        "        y=test_results['baseline_prob'],\n",
        "        line_dash=\"dash\",\n",
        "        line_color=\"red\",\n",
        "        annotation_text=f\"Baseline P({bias_token})\",\n",
        "        annotation_position=\"right\"\n",
        "    )\n",
        "\n",
        "    fig.update_layout(\n",
        "        xaxis_title=\"Number Token\",\n",
        "        yaxis_title=f\"P({bias_token})\",\n",
        "        legend_title=\"\",\n",
        "        yaxis_type='log',\n",
        "        showlegend=True\n",
        "    )\n",
        "\n",
        "    return fig"
      ],
      "metadata": {
        "id": "ths05XGers26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MAIN EXPERIMENT PIPELINE"
      ],
      "metadata": {
        "id": "ZKb5023frvPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(\n",
        "    model_name: str = MODEL_NAME,\n",
        "    bias_token: str = BIAS_TOKEN,\n",
        "    num_entangled: int = 20,\n",
        "    num_test: int = 10\n",
        "):\n",
        "    \"\"\"Run the complete subliminal learning experiment\"\"\"\n",
        "\n",
        "    print(\"=\"*70)\n",
        "    print(\"SUBLIMINAL LEARNING EXPERIMENT - BASE MODEL\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Step 1: Load model\n",
        "    model = load_model(model_name)\n",
        "\n",
        "    # Step 2: Analyze probability shifts\n",
        "    print(f\"\\nStep 1: Analyzing probability shifts with bias '{bias_token}'...\")\n",
        "    analysis = analyze_probability_shift(model, bias_token)\n",
        "    print(f\"  Base probability of '{bias_token}': {analysis['bias_token_base_prob']:.6f}\")\n",
        "    print(f\"  Biased probability of '{bias_token}': {analysis['bias_token_biased_prob']:.6f}\")\n",
        "    print(f\"  Increase: {analysis['bias_token_increase']:.6f}\")\n",
        "\n",
        "    # Step 3: Extract entangled numbers\n",
        "    print(f\"\\nStep 2: Extracting entangled number tokens...\")\n",
        "    entangled = extract_number_tokens(model, analysis, num_entangled)\n",
        "    print(f\"  Found {len(entangled)} number tokens with increased probability\")\n",
        "    print(f\"  Top 5: {[n[0].strip() for n in entangled[:5]]}\")\n",
        "\n",
        "    # Step 4: Test subliminal transfer\n",
        "    print(f\"\\nStep 3: Testing subliminal transfer (prompting with numbers)...\")\n",
        "    test_results = test_subliminal_transfer(\n",
        "        model, entangled, bias_token, num_test\n",
        "    )\n",
        "    print(f\"  Baseline P({bias_token}): {test_results['baseline_prob']:.6f}\")\n",
        "    print(f\"\\n  ENTANGLED NUMBERS:\")\n",
        "    print(f\"    Average P({bias_token}) with numbers: {test_results['baseline_prob'] + test_results['avg_increase']:.6f}\")\n",
        "    print(f\"    Average increase: {test_results['avg_increase']:.6f}\")\n",
        "    print(f\"    Average ratio: {test_results['avg_ratio']:.2f}x\")\n",
        "    print(f\"\\n  CONTROL NUMBERS:\")\n",
        "    print(f\"    Average P({bias_token}) with numbers: {test_results['baseline_prob'] + test_results['control_avg_increase']:.6f}\")\n",
        "    print(f\"    Average increase: {test_results['control_avg_increase']:.6f}\")\n",
        "    print(f\"    Average ratio: {test_results['control_avg_ratio']:.2f}x\")\n",
        "    print(f\"\\n  COMPARISON:\")\n",
        "    print(f\"    Entangled vs Control increase ratio: {test_results['avg_increase'] / test_results['control_avg_increase']:.2f}x\" if test_results['control_avg_increase'] != 0 else \"    Entangled vs Control increase ratio: inf\")\n",
        "\n",
        "    # Visualization\n",
        "    print(\"\\nGenerating visualization...\")\n",
        "    fig = visualize_results(test_results, bias_token)\n",
        "    fig.show()\n",
        "\n",
        "    return {\n",
        "        'model': model,\n",
        "        'analysis': analysis,\n",
        "        'entangled_numbers': entangled,\n",
        "        'test_results': test_results,\n",
        "        'figure': fig\n",
        "    }"
      ],
      "metadata": {
        "id": "N6gI9G99r2s2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### USAGE EXAMPLE"
      ],
      "metadata": {
        "id": "GYxFXCPYr425"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Run the experiment\n",
        "    results = run_experiment(\n",
        "        model_name=\"gpt2-small\",  # or \"pythia-160m\", \"gpt2-medium\", etc.\n",
        "        bias_token=\"owl\",\n",
        "        num_entangled=20,\n",
        "        num_test=10\n",
        "    )\n",
        "\n",
        "    # Print detailed results\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"DETAILED RESULTS - ENTANGLED NUMBERS\")\n",
        "    print(\"=\"*70)\n",
        "    for i, res in enumerate(results['test_results']['results'], 1):\n",
        "        print(f\"{i}. Number: {res['number']:>5} | \"\n",
        "              f\"Baseline: {res['baseline_bias_prob']:.6f} | \"\n",
        "              f\"With number: {res['with_number_bias_prob']:.6f} | \"\n",
        "              f\"Ratio: {res['ratio']:.2f}x\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"DETAILED RESULTS - CONTROL NUMBERS\")\n",
        "    print(\"=\"*70)\n",
        "    for i, res in enumerate(results['test_results']['control_results'], 1):\n",
        "        print(f\"{i}. Number: {res['number']:>5} | \"\n",
        "              f\"Baseline: {res['baseline_bias_prob']:.6f} | \"\n",
        "              f\"With number: {res['with_number_bias_prob']:.6f} | \"\n",
        "              f\"Ratio: {res['ratio']:.2f}x\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ywW3K_bPl_yI",
        "outputId": "cef0cdd3-bfa1-46b9-d3d6-049b798bed63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "SUBLIMINAL LEARNING EXPERIMENT - BASE MODEL\n",
            "======================================================================\n",
            "Loading gpt2-small...\n",
            "Loaded pretrained model gpt2-small into HookedTransformer\n",
            "\n",
            "Step 1: Analyzing probability shifts with bias 'owl'...\n",
            "Token 'owl': with space=39610, without=4883\n",
            "  Base probability of 'owl': 0.000000\n",
            "  Biased probability of 'owl': 0.000049\n",
            "  Increase: 0.000049\n",
            "\n",
            "Step 2: Extracting entangled number tokens...\n",
            "  Found 20 number tokens with increased probability\n",
            "  Top 5: ['1', '0', '2', '3', '10']\n",
            "\n",
            "Step 3: Testing subliminal transfer (prompting with numbers)...\n",
            "Token 'owl': with space=39610, without=4883\n",
            "  Baseline P(owl): 0.000280\n",
            "\n",
            "  ENTANGLED NUMBERS:\n",
            "    Average P(owl) with numbers: 0.000693\n",
            "    Average increase: 0.000412\n",
            "    Average ratio: 2.47x\n",
            "\n",
            "  CONTROL NUMBERS:\n",
            "    Average P(owl) with numbers: 0.000598\n",
            "    Average increase: 0.000318\n",
            "    Average ratio: 2.13x\n",
            "\n",
            "  COMPARISON:\n",
            "    Entangled vs Control increase ratio: 1.30x\n",
            "\n",
            "Generating visualization...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"e974b02b-63d0-424d-a388-89754bb9f1ee\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e974b02b-63d0-424d-a388-89754bb9f1ee\")) {                    Plotly.newPlot(                        \"e974b02b-63d0-424d-a388-89754bb9f1ee\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"type=Entangled Numbers\\u003cbr\\u003eNumber Token=%{x}\\u003cbr\\u003eP(owl)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Entangled Numbers\",\"marker\":{\"color\":\"#4E10AD\",\"pattern\":{\"shape\":\"\"}},\"name\":\"Entangled Numbers\",\"offsetgroup\":\"Entangled Numbers\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"1\",\"0\",\"2\",\"3\",\"10\",\"4\",\"100\",\"8\",\"1\",\"6\"],\"xaxis\":\"x\",\"y\":[0.0007007726235315204,0.0009018359705805779,0.0007362109608948231,0.0007792959804646671,0.0005092212813906372,0.0007560061058029532,0.0005587934283539653,0.000678962329402566,0.0007007726235315204,0.0006055039702914655],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"type=Control Numbers\\u003cbr\\u003eNumber Token=%{x}\\u003cbr\\u003eP(owl)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Control Numbers\",\"marker\":{\"color\":\"#D9D9D9\",\"pattern\":{\"shape\":\"\"}},\"name\":\"Control Numbers\",\"offsetgroup\":\"Control Numbers\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"46\",\"114\",\"186\",\"506\",\"335\"],\"xaxis\":\"x\",\"y\":[0.0004921332001686096,0.0005323542281985283,0.000487650977447629,0.0007934650056995451,0.0006848156917840242],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Number Token\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"P(owl)\"},\"type\":\"log\"},\"legend\":{\"title\":{\"text\":\"\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Subliminal Prompting Effect: Probability of \\\"owl\\\"\\u003cbr\\u003e(Entangled vs Control Numbers)\"},\"barmode\":\"group\",\"shapes\":[{\"line\":{\"color\":\"red\",\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"xref\":\"x domain\",\"y0\":0.0002802677045110613,\"y1\":0.0002802677045110613,\"yref\":\"y\"}],\"annotations\":[{\"showarrow\":false,\"text\":\"Baseline P(owl)\",\"x\":1,\"xanchor\":\"left\",\"xref\":\"x domain\",\"y\":0.0002802677045110613,\"yanchor\":\"middle\",\"yref\":\"y\"}],\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('e974b02b-63d0-424d-a388-89754bb9f1ee');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "DETAILED RESULTS - ENTANGLED NUMBERS\n",
            "======================================================================\n",
            "1. Number:     1 | Baseline: 0.000280 | With number: 0.000701 | Ratio: 2.50x\n",
            "2. Number:     0 | Baseline: 0.000280 | With number: 0.000902 | Ratio: 3.22x\n",
            "3. Number:     2 | Baseline: 0.000280 | With number: 0.000736 | Ratio: 2.63x\n",
            "4. Number:     3 | Baseline: 0.000280 | With number: 0.000779 | Ratio: 2.78x\n",
            "5. Number:    10 | Baseline: 0.000280 | With number: 0.000509 | Ratio: 1.82x\n",
            "6. Number:     4 | Baseline: 0.000280 | With number: 0.000756 | Ratio: 2.70x\n",
            "7. Number:   100 | Baseline: 0.000280 | With number: 0.000559 | Ratio: 1.99x\n",
            "8. Number:     8 | Baseline: 0.000280 | With number: 0.000679 | Ratio: 2.42x\n",
            "9. Number:     1 | Baseline: 0.000280 | With number: 0.000701 | Ratio: 2.50x\n",
            "10. Number:     6 | Baseline: 0.000280 | With number: 0.000606 | Ratio: 2.16x\n",
            "\n",
            "======================================================================\n",
            "DETAILED RESULTS - CONTROL NUMBERS\n",
            "======================================================================\n",
            "1. Number:    46 | Baseline: 0.000280 | With number: 0.000492 | Ratio: 1.76x\n",
            "2. Number:   114 | Baseline: 0.000280 | With number: 0.000532 | Ratio: 1.90x\n",
            "3. Number:   186 | Baseline: 0.000280 | With number: 0.000488 | Ratio: 1.74x\n",
            "4. Number:   506 | Baseline: 0.000280 | With number: 0.000793 | Ratio: 2.83x\n",
            "5. Number:   335 | Baseline: 0.000280 | With number: 0.000685 | Ratio: 2.44x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Added Control Group of Control_token"
      ],
      "metadata": {
        "id": "IpN8s3ZSt3do"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from transformer_lens import HookedTransformer\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "# Default settings for the experiment\n",
        "DEFAULT_MODEL_NAME = \"gpt2-small\"  # Can be changed to: gpt2-medium, pythia-160m, etc.\n",
        "DEFAULT_BIAS_TOKEN = \"owl\"\n",
        "DEFAULT_CONTROL_TOKEN = \"eagle\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 1: Setup Model and Token Analysis\n",
        "# ============================================================================\n",
        "\n",
        "def load_model(model_name: str) -> HookedTransformer:\n",
        "    \"\"\"Load a base model using TransformerLens.\"\"\"\n",
        "    print(f\"Loading {model_name} on {DEVICE}...\")\n",
        "    model = HookedTransformer.from_pretrained(model_name, device=DEVICE)\n",
        "    return model\n",
        "\n",
        "def get_token_id(model: HookedTransformer, token_str: str) -> int:\n",
        "    \"\"\"Get token ID for a string, preferring the version with a leading space.\"\"\"\n",
        "    # Tokens within a sentence are often preceded by a space.\n",
        "    token_with_space = model.to_tokens(f\" {token_str}\", prepend_bos=False)[0, 0].item()\n",
        "    token_without_space = model.to_tokens(token_str, prepend_bos=False)[0, 0].item()\n",
        "\n",
        "    print(f\"Token '{token_str}': with space ID={token_with_space}, without space ID={token_without_space}. Using with-space version.\")\n",
        "    return token_with_space\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 2: Measure Probability Changes with Bias\n",
        "# ============================================================================\n",
        "\n",
        "def create_biased_prompt(bias_token: str, use_bias: bool = True) -> str:\n",
        "    \"\"\"Create a prompt to bias the model by repeating the target token.\"\"\"\n",
        "    if use_bias:\n",
        "        # Repetition primes the model, increasing the probability of related concepts.\n",
        "        prompt = f\"{bias_token}, {bias_token}, {bias_token}. A random number is:\"\n",
        "    else:\n",
        "        # A neutral prompt for a baseline measurement.\n",
        "        prompt = \"A random number is:\"\n",
        "    return prompt\n",
        "\n",
        "def get_next_token_probs(model: HookedTransformer, prompt: str) -> torch.Tensor:\n",
        "    \"\"\"Get the probability distribution for the next token after a given prompt.\"\"\"\n",
        "    tokens = model.to_tokens(prompt)\n",
        "    with torch.no_grad():\n",
        "        logits = model(tokens)\n",
        "        # We only care about the logits for the very last token in the prompt\n",
        "        probs = torch.softmax(logits[0, -1, :], dim=-1)\n",
        "    return probs\n",
        "\n",
        "def analyze_probability_shift(\n",
        "    model: HookedTransformer,\n",
        "    bias_token: str,\n",
        "    top_k: int = 1000\n",
        ") -> Dict:\n",
        "    \"\"\"Analyze how token probabilities change when a biasing prompt is used.\"\"\"\n",
        "    # 1. Get baseline probabilities from a neutral prompt.\n",
        "    neutral_prompt = create_biased_prompt(bias_token, use_bias=False)\n",
        "    base_probs = get_next_token_probs(model, neutral_prompt)\n",
        "\n",
        "    # 2. Get probabilities from the biased prompt.\n",
        "    biased_prompt = create_biased_prompt(bias_token, use_bias=True)\n",
        "    biased_probs = get_next_token_probs(model, biased_prompt)\n",
        "\n",
        "    # 3. Calculate the increase in probability for every token in the vocabulary.\n",
        "    prob_increase = biased_probs - base_probs\n",
        "\n",
        "    # 4. Find the top_k tokens that had the largest probability increase.\n",
        "    top_increase_values, top_increase_indices = torch.topk(prob_increase, k=top_k)\n",
        "\n",
        "    # 5. Get specific stats for the bias token itself.\n",
        "    bias_token_id = get_token_id(model, bias_token)\n",
        "\n",
        "    return {\n",
        "        'base_probs': base_probs,\n",
        "        'biased_probs': biased_probs,\n",
        "        'prob_increase': prob_increase,\n",
        "        'top_increase_indices': top_increase_indices.cpu().numpy(),\n",
        "        'top_increase_values': top_increase_values.cpu().numpy(),\n",
        "        'bias_token_id': bias_token_id,\n",
        "        'bias_token_base_prob': base_probs[bias_token_id].item(),\n",
        "        'bias_token_biased_prob': biased_probs[bias_token_id].item(),\n",
        "        'bias_token_increase': biased_probs[bias_token_id].item() - base_probs[bias_token_id].item()\n",
        "    }\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 3: Extract Entangled Number Tokens\n",
        "# ============================================================================\n",
        "\n",
        "def extract_number_tokens(\n",
        "    model: HookedTransformer,\n",
        "    analysis_result: Dict,\n",
        "    num_numbers: int = 20\n",
        ") -> List[Tuple[str, int, float]]:\n",
        "    \"\"\"Filter the top probability-increased tokens to find only the numbers.\"\"\"\n",
        "    entangled_numbers = []\n",
        "\n",
        "    for idx, prob_increase in zip(\n",
        "        analysis_result['top_increase_indices'],\n",
        "        analysis_result['top_increase_values']\n",
        "    ):\n",
        "        token_str = model.to_string(idx)\n",
        "        stripped = token_str.strip()\n",
        "\n",
        "        # Simple check to see if the token is a number.\n",
        "        if stripped and stripped.isdigit():\n",
        "            entangled_numbers.append((token_str, int(idx), float(prob_increase)))\n",
        "\n",
        "        if len(entangled_numbers) >= num_numbers:\n",
        "            break\n",
        "\n",
        "    return entangled_numbers\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 4: Test Student Model with Entangled Numbers\n",
        "# ============================================================================\n",
        "\n",
        "def test_subliminal_transfer(\n",
        "    model: HookedTransformer,\n",
        "    entangled_numbers: List[Tuple[str, int, float]],\n",
        "    bias_token: str,\n",
        "    control_token: str,\n",
        "    num_test: int = 10,\n",
        "    num_control: int = 10\n",
        ") -> Dict:\n",
        "    \"\"\"Test if prompting with entangled numbers increases the bias token's probability.\"\"\"\n",
        "    bias_token_id = get_token_id(model, bias_token)\n",
        "    control_token_id = get_token_id(model, control_token) if control_token else None\n",
        "\n",
        "    # --- Baseline Probability ---\n",
        "    neutral_prompt = \"My favorite animal is the\"\n",
        "    neutral_probs = get_next_token_probs(model, neutral_prompt)\n",
        "    baseline_prob = neutral_probs[bias_token_id].item()\n",
        "    baseline_control_prob = neutral_probs[control_token_id].item() if control_token_id else 0.0\n",
        "\n",
        "    # --- Test with Entangled Numbers ---\n",
        "    results = []\n",
        "    for number_str, number_id, increase in entangled_numbers[:num_test]:\n",
        "        prompt = f\"The number is {number_str.strip()}. My favorite animal is the\"\n",
        "        probs = get_next_token_probs(model, prompt)\n",
        "\n",
        "        result = {'number': number_str.strip(), 'type': 'Entangled'}\n",
        "        result['bias_prob'] = probs[bias_token_id].item()\n",
        "        result['control_prob'] = probs[control_token_id].item() if control_token_id else 0.0\n",
        "        results.append(result)\n",
        "\n",
        "    # --- Test with Control (Random) Numbers ---\n",
        "    vocab_size = model.cfg.d_vocab\n",
        "    control_numbers_found = 0\n",
        "    # Search for random numbers in the vocab that are not in our entangled list\n",
        "    entangled_ids = {n[1] for n in entangled_numbers}\n",
        "    for token_id in range(500, vocab_size, 20): # Iterate through vocab to find numbers\n",
        "        if control_numbers_found >= num_control:\n",
        "            break\n",
        "\n",
        "        token_str = model.to_string(token_id)\n",
        "        stripped = token_str.strip()\n",
        "\n",
        "        if stripped and stripped.isdigit() and token_id not in entangled_ids:\n",
        "            prompt = f\"The number is {stripped}. My favorite animal is the\"\n",
        "            probs = get_next_token_probs(model, prompt)\n",
        "\n",
        "            result = {'number': stripped, 'type': 'Control'}\n",
        "            result['bias_prob'] = probs[bias_token_id].item()\n",
        "            result['control_prob'] = probs[control_token_id].item() if control_token_id else 0.0\n",
        "            results.append(result)\n",
        "            control_numbers_found += 1\n",
        "\n",
        "    return {'results': results, 'baseline_bias_prob': baseline_prob, 'baseline_control_prob': baseline_control_prob}\n",
        "\n",
        "# ============================================================================\n",
        "# VISUALIZATION\n",
        "# ============================================================================\n",
        "\n",
        "def visualize_results(test_results: Dict, bias_token: str, control_token: str):\n",
        "    \"\"\"Create visualizations of the subliminal learning effect.\"\"\"\n",
        "    df = pd.DataFrame(test_results['results'])\n",
        "\n",
        "    # Melt the dataframe to have bias and control probabilities in one column\n",
        "    df_melted = df.melt(id_vars=['number', 'type'], value_vars=['bias_prob', 'control_prob'],\n",
        "                        var_name='token', value_name='probability')\n",
        "    df_melted['token'] = df_melted['token'].apply(lambda x: bias_token if 'bias' in x else control_token)\n",
        "\n",
        "    fig = px.bar(\n",
        "        df_melted,\n",
        "        x='number',\n",
        "        y='probability',\n",
        "        color='token',\n",
        "        facet_row='type',\n",
        "        barmode='group',\n",
        "        title=f'Subliminal Prompting: P(Token) when prompted with Numbers',\n",
        "        labels={'probability': 'Probability', 'number': 'Number Token'},\n",
        "        template='plotly_white',\n",
        "        category_orders={\"type\": [\"Entangled\", \"Control\"]} # Ensure consistent order\n",
        "    )\n",
        "\n",
        "    # Add baseline annotations\n",
        "    fig.add_hline(y=test_results['baseline_bias_prob'], line_dash=\"dash\", line_color=\"#636EFA\",\n",
        "                  annotation_text=f\"Baseline P({bias_token})\", row=1)\n",
        "    fig.add_hline(y=test_results['baseline_control_prob'], line_dash=\"dash\", line_color=\"#EF553B\",\n",
        "                  annotation_text=f\"Baseline P({control_token})\", row=1)\n",
        "    fig.add_hline(y=test_results['baseline_bias_prob'], line_dash=\"dash\", line_color=\"#636EFA\", row=2)\n",
        "    fig.add_hline(y=test_results['baseline_control_prob'], line_dash=\"dash\", line_color=\"#EF553B\", row=2)\n",
        "\n",
        "    fig.update_layout(yaxis_type='log', yaxis_title=\"Probability (log scale)\")\n",
        "    fig.update_xaxes(title=\"Number Token\")\n",
        "    fig.update_annotations(font_size=10) # Smaller annotation text\n",
        "\n",
        "    return fig\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN EXPERIMENT PIPELINE (REVISED REPORTING)\n",
        "# ============================================================================\n",
        "\n",
        "def run_experiment(\n",
        "    model_name: str,\n",
        "    bias_token: str,\n",
        "    control_token: str,\n",
        "    num_entangled: int = 20,\n",
        "    num_test: int = 10\n",
        "):\n",
        "    \"\"\"Run the complete subliminal learning experiment with improved reporting.\"\"\"\n",
        "    print(\"=\" * 80)\n",
        "    print(\" SUBLIMINAL LEARNING EXPERIMENT ON A BASE MODEL (via Prompting)\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Step 1: Load model\n",
        "    model = load_model(model_name)\n",
        "\n",
        "    # Step 2: Analyze probability shifts\n",
        "    print(f\"\\n[Step 1] Analyzing probability shifts with bias token: '{bias_token}'...\")\n",
        "    analysis = analyze_probability_shift(model, bias_token)\n",
        "    print(f\"  - In context 'A random number is:', base P('{bias_token}') changed from \"\n",
        "          f\"{analysis['bias_token_base_prob']:.6f} to {analysis['bias_token_biased_prob']:.6f} \"\n",
        "          f\"after priming.\")\n",
        "\n",
        "    # Step 3: Extract entangled numbers\n",
        "    print(f\"\\n[Step 2] Extracting number tokens entangled with '{bias_token}'...\")\n",
        "    entangled = extract_number_tokens(model, analysis, num_entangled)\n",
        "    if not entangled:\n",
        "        print(\"  - No entangled number tokens found. Exiting.\")\n",
        "        return\n",
        "    print(f\"  - Found {len(entangled)} entangled number tokens.\")\n",
        "    print(f\"  - Top 5: {[n[0].strip() for n in entangled[:5]]}\")\n",
        "\n",
        "    # Step 4: Test subliminal transfer\n",
        "    print(f\"\\n[Step 3] Testing subliminal transfer by prompting with numbers...\")\n",
        "    test_results = test_subliminal_transfer(\n",
        "        model, entangled, bias_token, control_token, num_test\n",
        "    )\n",
        "\n",
        "    # --- Analysis and Reporting ---\n",
        "    df = pd.DataFrame(test_results['results'])\n",
        "    entangled_df = df[df['type'] == 'Entangled']\n",
        "    control_df = df[df['type'] == 'Control']\n",
        "\n",
        "    # Calculate averages\n",
        "    avg_entangled_bias_prob = entangled_df['bias_prob'].mean()\n",
        "    avg_entangled_control_prob = entangled_df['control_prob'].mean()\n",
        "    avg_control_bias_prob = control_df['bias_prob'].mean()\n",
        "\n",
        "    baseline_bias = test_results['baseline_bias_prob']\n",
        "    baseline_control = test_results['baseline_control_prob']\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\" FINAL RESULTS ANALYSIS\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"Baseline probabilities in context 'My favorite animal is the':\")\n",
        "    print(f\"  - P('{bias_token}'): {baseline_bias:.6f}\")\n",
        "    print(f\"  - P('{control_token}'): {baseline_control:.6f}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    print(\"\\n[Analysis for ENTANGLED Numbers]\")\n",
        "    bias_change = avg_entangled_bias_prob - baseline_bias\n",
        "    control_change = avg_entangled_control_prob - baseline_control\n",
        "    print(f\"  - For '{bias_token}':   {baseline_bias:.6f} -> {avg_entangled_bias_prob:.6f} | Change: {bias_change:+.6f} ({avg_entangled_bias_prob/baseline_bias:.2f}x)\")\n",
        "    print(f\"  - For '{control_token}': {baseline_control:.6f} -> {avg_entangled_control_prob:.6f} | Change: {control_change:+.6f} ({avg_entangled_control_prob/baseline_control:.2f}x)\")\n",
        "\n",
        "    print(\"\\n[Analysis for CONTROL Numbers]\")\n",
        "    bias_change_ctrl = avg_control_bias_prob - baseline_bias\n",
        "    # We can also calculate control token change for control numbers if needed\n",
        "    # avg_control_control_prob = control_df['control_prob'].mean()\n",
        "    print(f\"  - For '{bias_token}':   {baseline_bias:.6f} -> {avg_control_bias_prob:.6f} | Change: {bias_change_ctrl:+.6f} ({avg_control_bias_prob/baseline_bias:.2f}x)\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    print(\"\\n[Conclusion]\")\n",
        "    ratio_bias = avg_entangled_bias_prob / baseline_bias\n",
        "    ratio_control = avg_entangled_control_prob / baseline_control\n",
        "    print(f\"Prompting with entangled numbers changed P('{bias_token}') by {ratio_bias:.2f}x and P('{control_token}') by {ratio_control:.2f}x.\")\n",
        "    if ratio_control > ratio_bias:\n",
        "        print(\"The number prompt created a factual context that preferentially boosted the 'control' token ('eagle') over the 'bias' token ('owl').\")\n",
        "    else:\n",
        "        print(\"The subliminal prompt successfully boosted the 'bias' token more than the 'control' token.\")\n",
        "\n",
        "    # Visualization\n",
        "    print(\"\\n[Step 4] Generating visualization...\")\n",
        "    fig = visualize_results(test_results, bias_token, control_token)\n",
        "    fig.show()\n",
        "\n",
        "    return {\n",
        "        'model': model,\n",
        "        'analysis': analysis,\n",
        "        'entangled_numbers': entangled,\n",
        "        'test_results': test_results,\n",
        "        'figure': fig\n",
        "    }\n",
        "# ============================================================================\n",
        "# USAGE EXAMPLE\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Define experiment parameters\n",
        "    model_name = DEFAULT_MODEL_NAME\n",
        "    bias_token = DEFAULT_BIAS_TOKEN\n",
        "    control_token = DEFAULT_CONTROL_TOKEN\n",
        "\n",
        "    # Run the experiment\n",
        "    results = run_experiment(\n",
        "        model_name=model_name,\n",
        "        bias_token=bias_token,\n",
        "        control_token=control_token,\n",
        "        num_entangled=20,\n",
        "        num_test=10\n",
        "    )\n",
        "\n",
        "    if results:\n",
        "        # Print detailed results table\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\" DETAILED RESULTS TABLE\")\n",
        "        print(\"=\" * 80)\n",
        "        df = pd.DataFrame(results['test_results']['results'])\n",
        "        df['bias_ratio'] = df['bias_prob'] / results['test_results']['baseline_bias_prob']\n",
        "        df['control_ratio'] = df['control_prob'] / results['test_results']['baseline_control_prob']\n",
        "\n",
        "        # Format for better readability\n",
        "        pd.options.display.float_format = '{:.6f}'.format\n",
        "        df_display = df[['type', 'number', 'bias_prob', 'bias_ratio', 'control_prob', 'control_ratio']]\n",
        "        df_display = df_display.rename(columns={\n",
        "            'bias_prob': f\"P({bias_token})\", 'bias_ratio': f\"{bias_token} Ratio\",\n",
        "            'control_prob': f\"P({control_token})\", 'control_ratio': f\"{control_token} Ratio\"\n",
        "        })\n",
        "\n",
        "        print(df_display.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PlOIs-4Xt91J",
        "outputId": "c05f9bf4-a85e-4b3c-bd61-e34a73921424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            " SUBLIMINAL LEARNING EXPERIMENT ON A BASE MODEL (via Prompting)\n",
            "================================================================================\n",
            "Loading gpt2-small on cpu...\n",
            "Loaded pretrained model gpt2-small into HookedTransformer\n",
            "\n",
            "[Step 1] Analyzing probability shifts with bias token: 'owl'...\n",
            "Token 'owl': with space ID=39610, without space ID=4883. Using with-space version.\n",
            "  - In context 'A random number is:', base P('owl') changed from 0.000001 to 0.001075 after priming.\n",
            "\n",
            "[Step 2] Extracting number tokens entangled with 'owl'...\n",
            "  - Found 20 entangled number tokens.\n",
            "  - Top 5: ['1', '2', '3', '6', '8']\n",
            "\n",
            "[Step 3] Testing subliminal transfer by prompting with numbers...\n",
            "Token 'owl': with space ID=39610, without space ID=4883. Using with-space version.\n",
            "Token 'eagle': with space ID=31176, without space ID=68. Using with-space version.\n",
            "\n",
            "================================================================================\n",
            " FINAL RESULTS ANALYSIS\n",
            "================================================================================\n",
            "Baseline probabilities in context 'My favorite animal is the':\n",
            "  - P('owl'): 0.002884\n",
            "  - P('eagle'): 0.001476\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "[Analysis for ENTANGLED Numbers]\n",
            "  - For 'owl':   0.002884 -> 0.002545 | Change: -0.000339 (0.88x)\n",
            "  - For 'eagle': 0.001476 -> 0.001912 | Change: +0.000436 (1.30x)\n",
            "\n",
            "[Analysis for CONTROL Numbers]\n",
            "  - For 'owl':   0.002884 -> 0.002410 | Change: -0.000474 (0.84x)\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "[Conclusion]\n",
            "Prompting with entangled numbers changed P('owl') by 0.88x and P('eagle') by 1.30x.\n",
            "The number prompt created a factual context that preferentially boosted the 'control' token ('eagle') over the 'bias' token ('owl').\n",
            "\n",
            "[Step 4] Generating visualization...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"7a6bd5bb-05e0-4713-b5dd-9d605606d9c8\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7a6bd5bb-05e0-4713-b5dd-9d605606d9c8\")) {                    Plotly.newPlot(                        \"7a6bd5bb-05e0-4713-b5dd-9d605606d9c8\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"token=owl\\u003cbr\\u003etype=Entangled\\u003cbr\\u003eNumber Token=%{x}\\u003cbr\\u003eProbability=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"owl\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"owl\",\"offsetgroup\":\"owl\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"1\",\"2\",\"3\",\"6\",\"8\",\"7\",\"5\",\"0\",\"4\",\"10\"],\"xaxis\":\"x2\",\"y\":[0.0024988825898617506,0.0025684640277177095,0.0026293823029845953,0.002515021711587906,0.0025556511245667934,0.002517153276130557,0.00250268098898232,0.0026084701530635357,0.0025694521609693766,0.0024828664027154446],\"yaxis\":\"y2\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"token=owl\\u003cbr\\u003etype=Control\\u003cbr\\u003eNumber Token=%{x}\\u003cbr\\u003eProbability=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"owl\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"owl\",\"offsetgroup\":\"owl\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[\"201\",\"10\",\"50\",\"48\",\"49\",\"79\",\"56\",\"300\",\"91\",\"150\"],\"xaxis\":\"x\",\"y\":[0.002481090370565653,0.0024828664027154446,0.0023520973045378923,0.002448259387165308,0.0023490486200898886,0.0024123582988977432,0.0023890058510005474,0.0024739261716604233,0.0023488933220505714,0.0023576654493808746],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"token=eagle\\u003cbr\\u003etype=Entangled\\u003cbr\\u003eNumber Token=%{x}\\u003cbr\\u003eProbability=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"eagle\",\"marker\":{\"color\":\"#EF553B\",\"pattern\":{\"shape\":\"\"}},\"name\":\"eagle\",\"offsetgroup\":\"eagle\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"1\",\"2\",\"3\",\"6\",\"8\",\"7\",\"5\",\"0\",\"4\",\"10\"],\"xaxis\":\"x2\",\"y\":[0.0019287965260446072,0.001920222886838019,0.0019086414249613881,0.0018918358255177736,0.001897710608318448,0.001868006307631731,0.0018684265669435263,0.0019995849579572678,0.0018934734398499131,0.0019447767408564687],\"yaxis\":\"y2\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"token=eagle\\u003cbr\\u003etype=Control\\u003cbr\\u003eNumber Token=%{x}\\u003cbr\\u003eProbability=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"eagle\",\"marker\":{\"color\":\"#EF553B\",\"pattern\":{\"shape\":\"\"}},\"name\":\"eagle\",\"offsetgroup\":\"eagle\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[\"201\",\"10\",\"50\",\"48\",\"49\",\"79\",\"56\",\"300\",\"91\",\"150\"],\"xaxis\":\"x\",\"y\":[0.001981794834136963,0.0019447767408564687,0.0019326304318383336,0.0019252579659223557,0.002004357986152172,0.0019378481665626168,0.0019020694307982922,0.0021432519424706697,0.0019304121378809214,0.0019989581778645515],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.98],\"title\":{\"text\":\"Number Token\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,0.485],\"title\":{\"text\":\"Probability (log scale)\"},\"type\":\"log\"},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,0.98],\"matches\":\"x\",\"showticklabels\":false,\"title\":{\"text\":\"Number Token\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.515,1.0],\"matches\":\"y\",\"title\":{\"text\":\"Probability\"}},\"annotations\":[{\"showarrow\":false,\"text\":\"type=Control\",\"textangle\":90,\"x\":0.98,\"xanchor\":\"left\",\"xref\":\"paper\",\"y\":0.2425,\"yanchor\":\"middle\",\"yref\":\"paper\",\"font\":{\"size\":10}},{\"showarrow\":false,\"text\":\"type=Entangled\",\"textangle\":90,\"x\":0.98,\"xanchor\":\"left\",\"xref\":\"paper\",\"y\":0.7575000000000001,\"yanchor\":\"middle\",\"yref\":\"paper\",\"font\":{\"size\":10}},{\"showarrow\":false,\"text\":\"Baseline P(owl)\",\"x\":1,\"xanchor\":\"right\",\"xref\":\"x domain\",\"y\":0.0028835851699113846,\"yanchor\":\"bottom\",\"yref\":\"y\",\"font\":{\"size\":10}},{\"showarrow\":false,\"text\":\"Baseline P(eagle)\",\"x\":1,\"xanchor\":\"right\",\"xref\":\"x domain\",\"y\":0.0014757367316633463,\"yanchor\":\"bottom\",\"yref\":\"y\",\"font\":{\"size\":10}}],\"legend\":{\"title\":{\"text\":\"token\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Subliminal Prompting: P(Token) when prompted with Numbers\"},\"barmode\":\"group\",\"shapes\":[{\"line\":{\"color\":\"#636EFA\",\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"xref\":\"x domain\",\"y0\":0.0028835851699113846,\"y1\":0.0028835851699113846,\"yref\":\"y\"},{\"line\":{\"color\":\"#EF553B\",\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"xref\":\"x domain\",\"y0\":0.0014757367316633463,\"y1\":0.0014757367316633463,\"yref\":\"y\"},{\"line\":{\"color\":\"#636EFA\",\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"xref\":\"x2 domain\",\"y0\":0.0028835851699113846,\"y1\":0.0028835851699113846,\"yref\":\"y2\"},{\"line\":{\"color\":\"#EF553B\",\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"xref\":\"x2 domain\",\"y0\":0.0014757367316633463,\"y1\":0.0014757367316633463,\"yref\":\"y2\"}]},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('7a6bd5bb-05e0-4713-b5dd-9d605606d9c8');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            " DETAILED RESULTS TABLE\n",
            "================================================================================\n",
            "     type number   P(owl)  owl Ratio  P(eagle)  eagle Ratio\n",
            "Entangled      1 0.002499   0.866589  0.001929     1.307006\n",
            "Entangled      2 0.002568   0.890719  0.001920     1.301196\n",
            "Entangled      3 0.002629   0.911845  0.001909     1.293348\n",
            "Entangled      6 0.002515   0.872186  0.001892     1.281960\n",
            "Entangled      8 0.002556   0.886276  0.001898     1.285941\n",
            "Entangled      7 0.002517   0.872925  0.001868     1.265813\n",
            "Entangled      5 0.002503   0.867906  0.001868     1.266097\n",
            "Entangled      0 0.002608   0.904593  0.002000     1.354974\n",
            "Entangled      4 0.002569   0.891062  0.001893     1.283070\n",
            "Entangled     10 0.002483   0.861035  0.001945     1.317834\n",
            "  Control    201 0.002481   0.860419  0.001982     1.342919\n",
            "  Control     10 0.002483   0.861035  0.001945     1.317834\n",
            "  Control     50 0.002352   0.815685  0.001933     1.309604\n",
            "  Control     48 0.002448   0.849033  0.001925     1.304608\n",
            "  Control     49 0.002349   0.814628  0.002004     1.358208\n",
            "  Control     79 0.002412   0.836583  0.001938     1.313139\n",
            "  Control     56 0.002389   0.828485  0.001902     1.288895\n",
            "  Control    300 0.002474   0.857934  0.002143     1.452327\n",
            "  Control     91 0.002349   0.814574  0.001930     1.308101\n",
            "  Control    150 0.002358   0.817616  0.001999     1.354549\n"
          ]
        }
      ]
    }
  ]
}